{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd1c46d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d710c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Credit Card Fraud Detection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25322d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_df = pd.read_csv(\"creditcardfraud.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15fc3789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82450</td>\n",
       "      <td>1.314539</td>\n",
       "      <td>0.590643</td>\n",
       "      <td>-0.666593</td>\n",
       "      <td>0.716564</td>\n",
       "      <td>0.301978</td>\n",
       "      <td>-1.125467</td>\n",
       "      <td>0.388881</td>\n",
       "      <td>-0.288390</td>\n",
       "      <td>-0.132137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170307</td>\n",
       "      <td>-0.429655</td>\n",
       "      <td>-0.141341</td>\n",
       "      <td>-0.200195</td>\n",
       "      <td>0.639491</td>\n",
       "      <td>0.399476</td>\n",
       "      <td>-0.034321</td>\n",
       "      <td>0.031692</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50554</td>\n",
       "      <td>-0.798672</td>\n",
       "      <td>1.185093</td>\n",
       "      <td>0.904547</td>\n",
       "      <td>0.694584</td>\n",
       "      <td>0.219041</td>\n",
       "      <td>-0.319295</td>\n",
       "      <td>0.495236</td>\n",
       "      <td>0.139269</td>\n",
       "      <td>-0.760214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202287</td>\n",
       "      <td>0.578699</td>\n",
       "      <td>-0.092245</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>-0.246466</td>\n",
       "      <td>-0.380057</td>\n",
       "      <td>-0.396030</td>\n",
       "      <td>-0.112901</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55125</td>\n",
       "      <td>-0.391128</td>\n",
       "      <td>-0.245540</td>\n",
       "      <td>1.122074</td>\n",
       "      <td>-1.308725</td>\n",
       "      <td>-0.639891</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>-0.701304</td>\n",
       "      <td>-0.027315</td>\n",
       "      <td>-2.628854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133485</td>\n",
       "      <td>0.117403</td>\n",
       "      <td>-0.191748</td>\n",
       "      <td>-0.488642</td>\n",
       "      <td>-0.309774</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.163716</td>\n",
       "      <td>0.239582</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116572</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>1.065093</td>\n",
       "      <td>-0.987421</td>\n",
       "      <td>-0.029567</td>\n",
       "      <td>0.176376</td>\n",
       "      <td>-1.348539</td>\n",
       "      <td>0.775644</td>\n",
       "      <td>0.134843</td>\n",
       "      <td>-0.149734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355576</td>\n",
       "      <td>0.907570</td>\n",
       "      <td>-0.018454</td>\n",
       "      <td>-0.126269</td>\n",
       "      <td>-0.339923</td>\n",
       "      <td>-0.150285</td>\n",
       "      <td>-0.023634</td>\n",
       "      <td>0.042330</td>\n",
       "      <td>57.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90434</td>\n",
       "      <td>1.848433</td>\n",
       "      <td>0.373364</td>\n",
       "      <td>0.269272</td>\n",
       "      <td>3.866438</td>\n",
       "      <td>0.088062</td>\n",
       "      <td>0.970447</td>\n",
       "      <td>-0.721945</td>\n",
       "      <td>0.235983</td>\n",
       "      <td>0.683491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103563</td>\n",
       "      <td>0.620954</td>\n",
       "      <td>0.197077</td>\n",
       "      <td>0.692392</td>\n",
       "      <td>-0.206530</td>\n",
       "      <td>-0.021328</td>\n",
       "      <td>-0.019823</td>\n",
       "      <td>-0.042682</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>160243</td>\n",
       "      <td>-2.783865</td>\n",
       "      <td>1.596824</td>\n",
       "      <td>-2.084844</td>\n",
       "      <td>2.512986</td>\n",
       "      <td>-1.446749</td>\n",
       "      <td>-0.828496</td>\n",
       "      <td>-0.732262</td>\n",
       "      <td>-0.203329</td>\n",
       "      <td>-0.347046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203563</td>\n",
       "      <td>0.293268</td>\n",
       "      <td>0.199568</td>\n",
       "      <td>0.146868</td>\n",
       "      <td>0.163602</td>\n",
       "      <td>-0.624085</td>\n",
       "      <td>-1.333100</td>\n",
       "      <td>0.428634</td>\n",
       "      <td>156.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>110547</td>\n",
       "      <td>-1.532810</td>\n",
       "      <td>2.232752</td>\n",
       "      <td>-5.923100</td>\n",
       "      <td>3.386708</td>\n",
       "      <td>-0.153443</td>\n",
       "      <td>-1.419748</td>\n",
       "      <td>-3.878576</td>\n",
       "      <td>1.444656</td>\n",
       "      <td>-1.465542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632505</td>\n",
       "      <td>-0.070838</td>\n",
       "      <td>-0.490291</td>\n",
       "      <td>-0.359983</td>\n",
       "      <td>0.050678</td>\n",
       "      <td>1.095671</td>\n",
       "      <td>0.471741</td>\n",
       "      <td>-0.106667</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>70071</td>\n",
       "      <td>-0.440095</td>\n",
       "      <td>1.137239</td>\n",
       "      <td>-3.227080</td>\n",
       "      <td>3.242293</td>\n",
       "      <td>-2.033998</td>\n",
       "      <td>-1.618415</td>\n",
       "      <td>-3.028013</td>\n",
       "      <td>0.764555</td>\n",
       "      <td>-1.801937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764187</td>\n",
       "      <td>-0.275578</td>\n",
       "      <td>-0.343572</td>\n",
       "      <td>0.233085</td>\n",
       "      <td>0.606434</td>\n",
       "      <td>-0.315433</td>\n",
       "      <td>0.768291</td>\n",
       "      <td>0.459623</td>\n",
       "      <td>227.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>93879</td>\n",
       "      <td>-13.086519</td>\n",
       "      <td>7.352148</td>\n",
       "      <td>-18.256576</td>\n",
       "      <td>10.648505</td>\n",
       "      <td>-11.731476</td>\n",
       "      <td>-3.659167</td>\n",
       "      <td>-14.873658</td>\n",
       "      <td>8.810473</td>\n",
       "      <td>-5.418204</td>\n",
       "      <td>...</td>\n",
       "      <td>2.761157</td>\n",
       "      <td>-0.266162</td>\n",
       "      <td>-0.412861</td>\n",
       "      <td>0.519952</td>\n",
       "      <td>-0.743909</td>\n",
       "      <td>-0.167808</td>\n",
       "      <td>-2.498300</td>\n",
       "      <td>-0.711066</td>\n",
       "      <td>30.31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>50706</td>\n",
       "      <td>-8.461845</td>\n",
       "      <td>6.866198</td>\n",
       "      <td>-11.838269</td>\n",
       "      <td>4.194211</td>\n",
       "      <td>-6.923097</td>\n",
       "      <td>-3.221147</td>\n",
       "      <td>-7.553497</td>\n",
       "      <td>6.015618</td>\n",
       "      <td>-2.466143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918244</td>\n",
       "      <td>-0.715366</td>\n",
       "      <td>0.210747</td>\n",
       "      <td>-0.060211</td>\n",
       "      <td>0.509535</td>\n",
       "      <td>-0.257284</td>\n",
       "      <td>1.170027</td>\n",
       "      <td>0.229301</td>\n",
       "      <td>99.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time         V1        V2         V3         V4         V5        V6  \\\n",
       "0     82450   1.314539  0.590643  -0.666593   0.716564   0.301978 -1.125467   \n",
       "1     50554  -0.798672  1.185093   0.904547   0.694584   0.219041 -0.319295   \n",
       "2     55125  -0.391128 -0.245540   1.122074  -1.308725  -0.639891  0.008678   \n",
       "3    116572  -0.060302  1.065093  -0.987421  -0.029567   0.176376 -1.348539   \n",
       "4     90434   1.848433  0.373364   0.269272   3.866438   0.088062  0.970447   \n",
       "..      ...        ...       ...        ...        ...        ...       ...   \n",
       "595  160243  -2.783865  1.596824  -2.084844   2.512986  -1.446749 -0.828496   \n",
       "596  110547  -1.532810  2.232752  -5.923100   3.386708  -0.153443 -1.419748   \n",
       "597   70071  -0.440095  1.137239  -3.227080   3.242293  -2.033998 -1.618415   \n",
       "598   93879 -13.086519  7.352148 -18.256576  10.648505 -11.731476 -3.659167   \n",
       "599   50706  -8.461845  6.866198 -11.838269   4.194211  -6.923097 -3.221147   \n",
       "\n",
       "            V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0     0.388881 -0.288390 -0.132137  ... -0.170307 -0.429655 -0.141341   \n",
       "1     0.495236  0.139269 -0.760214  ...  0.202287  0.578699 -0.092245   \n",
       "2    -0.701304 -0.027315 -2.628854  ... -0.133485  0.117403 -0.191748   \n",
       "3     0.775644  0.134843 -0.149734  ...  0.355576  0.907570 -0.018454   \n",
       "4    -0.721945  0.235983  0.683491  ...  0.103563  0.620954  0.197077   \n",
       "..         ...       ...       ...  ...       ...       ...       ...   \n",
       "595  -0.732262 -0.203329 -0.347046  ...  0.203563  0.293268  0.199568   \n",
       "596  -3.878576  1.444656 -1.465542  ...  0.632505 -0.070838 -0.490291   \n",
       "597  -3.028013  0.764555 -1.801937  ...  0.764187 -0.275578 -0.343572   \n",
       "598 -14.873658  8.810473 -5.418204  ...  2.761157 -0.266162 -0.412861   \n",
       "599  -7.553497  6.015618 -2.466143  ...  0.918244 -0.715366  0.210747   \n",
       "\n",
       "          V24       V25       V26       V27       V28  Amount  Class  \n",
       "0   -0.200195  0.639491  0.399476 -0.034321  0.031692    0.76      0  \n",
       "1    0.013723 -0.246466 -0.380057 -0.396030 -0.112901    4.18      0  \n",
       "2   -0.488642 -0.309774  0.008100  0.163716  0.239582   15.00      0  \n",
       "3   -0.126269 -0.339923 -0.150285 -0.023634  0.042330   57.00      0  \n",
       "4    0.692392 -0.206530 -0.021328 -0.019823 -0.042682    0.00      0  \n",
       "..        ...       ...       ...       ...       ...     ...    ...  \n",
       "595  0.146868  0.163602 -0.624085 -1.333100  0.428634  156.00      1  \n",
       "596 -0.359983  0.050678  1.095671  0.471741 -0.106667    0.76      1  \n",
       "597  0.233085  0.606434 -0.315433  0.768291  0.459623  227.30      1  \n",
       "598  0.519952 -0.743909 -0.167808 -2.498300 -0.711066   30.31      1  \n",
       "599 -0.060211  0.509535 -0.257284  1.170027  0.229301   99.99      1  \n",
       "\n",
       "[600 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_card_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecd752c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d94cba8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_card_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0af1d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Time column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d53b358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_df = credit_card_df.drop(columns=[\"Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56fc76c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the Amount column using a standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c02fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "credit_card_df[\"Amount\"] = scaler.fit_transform(credit_card_df[[\"Amount\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e43ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating features (x) and target variable (y: Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6392f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = credit_card_df.drop(columns=[\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c53fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = credit_card_df[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e2777de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (80:20 split ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adffd178",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f57162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a logistic regression model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ede6355d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de597e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate logistic regression model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77cae6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logistic = logistic_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14b28401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance using confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fdd8054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Evaluation: Credit Card Fraud Detection\n",
      "Confusion Matrix:\n",
      " [[59  3]\n",
      " [ 4 54]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94        62\n",
      "           1       0.95      0.93      0.94        58\n",
      "\n",
      "    accuracy                           0.94       120\n",
      "   macro avg       0.94      0.94      0.94       120\n",
      "weighted avg       0.94      0.94      0.94       120\n",
      "\n",
      "Accuracy Score: 0.9416666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Evaluation: Credit Card Fraud Detection\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_logistic))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_logistic))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83bd8bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an SVM model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a033ad92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = SVC()\n",
    "svm_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9195b8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate SVM model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "073c35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa593703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance using confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d87b1b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Evaluation: Credit Card Fraud Detection\n",
      "Confusion Matrix:\n",
      " [[62  0]\n",
      " [ 6 52]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        62\n",
      "           1       1.00      0.90      0.95        58\n",
      "\n",
      "    accuracy                           0.95       120\n",
      "   macro avg       0.96      0.95      0.95       120\n",
      "weighted avg       0.95      0.95      0.95       120\n",
      "\n",
      "Accuracy Score: 0.95\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSVM Evaluation: Credit Card Fraud Detection\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8c3e907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune hyperparameters using grid search cross-validation\n",
    "# For Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6df6e36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mithilkatkar/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mithilkatkar/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mithilkatkar/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mithilkatkar/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mithilkatkar/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "param_grid_logistic = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid_search_logistic = GridSearchCV(LogisticRegression(), param_grid_logistic, cv=5, scoring='accuracy')\n",
    "grid_search_logistic.fit(x_train, y_train)\n",
    "best_logistic_model = grid_search_logistic.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a58bba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32abba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svm = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10]}\n",
    "grid_search_svm = GridSearchCV(SVC(), param_grid_svm, cv=5, scoring='accuracy')\n",
    "grid_search_svm.fit(x_train, y_train)\n",
    "best_svm_model = grid_search_svm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f4ab721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models with optimal hyperparameters and evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "290b4e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, gamma=0.1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_logistic_model.fit(x_train, y_train)\n",
    "best_svm_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52b271dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logistic_best = best_logistic_model.predict(x_test)\n",
    "y_pred_svm_best = best_svm_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bde3a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1eadcf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Logistic Regression Model Evaluation: Credit Card Fraud Detection\n",
      "Confusion Matrix:\n",
      " [[61  1]\n",
      " [ 4 54]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        62\n",
      "           1       0.98      0.93      0.96        58\n",
      "\n",
      "    accuracy                           0.96       120\n",
      "   macro avg       0.96      0.96      0.96       120\n",
      "weighted avg       0.96      0.96      0.96       120\n",
      "\n",
      "Accuracy Score: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Logistic Regression Model Evaluation: Credit Card Fraud Detection\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_logistic_best))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_logistic_best))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred_logistic_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a87ba9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best SVM Model Evaluation: Credit Card Fraud Detection\n",
      "Confusion Matrix:\n",
      " [[54  8]\n",
      " [ 1 57]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92        62\n",
      "           1       0.88      0.98      0.93        58\n",
      "\n",
      "    accuracy                           0.93       120\n",
      "   macro avg       0.93      0.93      0.92       120\n",
      "weighted avg       0.93      0.93      0.92       120\n",
      "\n",
      "Accuracy Score: 0.925\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest SVM Model Evaluation: Credit Card Fraud Detection\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm_best))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_svm_best))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred_svm_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa0f136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the performance of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cb5f540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison: Credit Card Fraud Detection\n",
      "Logistic Regression Model Accuracy: 0.9583333333333334\n",
      "SVM Model Accuracy: 0.925\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel Comparison: Credit Card Fraud Detection\")\n",
    "print(\"Logistic Regression Model Accuracy:\", accuracy_score(y_test, y_pred_logistic_best))\n",
    "print(\"SVM Model Accuracy:\", accuracy_score(y_test, y_pred_svm_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c3766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
